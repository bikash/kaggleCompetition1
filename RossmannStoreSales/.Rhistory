### Simulation & Modeling of Hidden Markov Model (HMM)
library(TeachingDemos)
library(HMM)
library(ggplot2)
set.seed(1)
### Define our variables
TPM <- matrix(c(.95, .05,
.1, .9), 2, byrow = TRUE)
EPM <- matrix(c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6,
1/10, 1/10, 1/10, 1/10, 1/10, 1/2), 2, byrow = TRUE)
simulations <- 500
### Create a dataframe to hold our results
dice <- rep(NA, simulations)
number <- rep.int(0, simulations)
results <- data.frame(dice, number)
### Simulate
# Assume we start with a fair dice
state <- "FAIR"
for (i in 1:simulations) {
if (state == "FAIR") {
# Check to see if we're staying with a FAIR dice
p <- runif(1)
if (p <= TPM[1,2]) {
# If not, roll loaded dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[2,])[[1]]
# Remember new state
state <- "LOADED"
}
else {
# Roll fair dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[1,])[[1]]
# Remember old state
state <- "FAIR"
}
}
if (state == "LOADED") {
# Check to see if we're staying with a LOADED dice
p <- runif(1)
if (p < TPM[2,1]) {
# If not, roll fair dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[1,])[[1]]
# Remember new state
state <- "FAIR"
}
else {
# Roll loaded dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[2,])[[1]]
# Remember old state
state <- "LOADED"
}
}
# Save dice roll and state
results[i, 1] <- state
results[i, 2] <- roll
}
install.packages("TeachingDemos")
### Simulation & Modeling of Hidden Markov Model (HMM)
library(TeachingDemos)
library(HMM)
library(ggplot2)
set.seed(1)
### Define our variables
TPM <- matrix(c(.95, .05,
.1, .9), 2, byrow = TRUE)
EPM <- matrix(c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6,
1/10, 1/10, 1/10, 1/10, 1/10, 1/2), 2, byrow = TRUE)
simulations <- 500
### Create a dataframe to hold our results
dice <- rep(NA, simulations)
number <- rep.int(0, simulations)
results <- data.frame(dice, number)
### Simulate
# Assume we start with a fair dice
state <- "FAIR"
for (i in 1:simulations) {
if (state == "FAIR") {
# Check to see if we're staying with a FAIR dice
p <- runif(1)
if (p <= TPM[1,2]) {
# If not, roll loaded dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[2,])[[1]]
# Remember new state
state <- "LOADED"
}
else {
# Roll fair dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[1,])[[1]]
# Remember old state
state <- "FAIR"
}
}
if (state == "LOADED") {
# Check to see if we're staying with a LOADED dice
p <- runif(1)
if (p < TPM[2,1]) {
# If not, roll fair dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[1,])[[1]]
# Remember new state
state <- "FAIR"
}
else {
# Roll loaded dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[2,])[[1]]
# Remember old state
state <- "LOADED"
}
}
# Save dice roll and state
results[i, 1] <- state
results[i, 2] <- roll
}
### Simulation & Modeling of Hidden Markov Model (HMM)
library(TeachingDemos)
library(HMM)
library(ggplot2)
set.seed(1)
### Define our variables
TPM <- matrix(c(.95, .05,
.1, .9), 2, byrow = TRUE)
EPM <- matrix(c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6,
1/10, 1/10, 1/10, 1/10, 1/10, 1/2), 2, byrow = TRUE)
simulations <- 500
### Create a dataframe to hold our results
dice <- rep(NA, simulations)
number <- rep.int(0, simulations)
results <- data.frame(dice, number)
### Simulate
# Assume we start with a fair dice
state <- "FAIR"
for (i in 1:simulations) {
if (state == "FAIR") {
# Check to see if we're staying with a FAIR dice
p <- runif(1)
if (p <= TPM[1,2]) {
# If not, roll loaded dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[2,])[[1]]
# Remember new state
state <- "LOADED"
}
else {
# Roll fair dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[1,])[[1]]
# Remember old state
state <- "FAIR"
}
}
if (state == "LOADED") {
# Check to see if we're staying with a LOADED dice
p <- runif(1)
if (p < TPM[2,1]) {
# If not, roll fair dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[1,])[[1]]
# Remember new state
state <- "FAIR"
}
else {
# Roll loaded dice
roll <- dice(rolls = 1, ndice = 1, sides = 6, load = EPM[2,])[[1]]
# Remember old state
state <- "LOADED"
}
}
# Save dice roll and state
results[i, 1] <- state
results[i, 2] <- roll
}
### Modeling
# Create hmm using our TPM/EPM
hmm <- initHMM(c("FAIR", "LOADED"), c(1, 2, 3, 4, 5, 6),
transProbs = TPM, emissionProbs = EPM)
# Pull in results from the simulation
obs <- results[, 2]
# Save Viterbi/Posterior predictions as a new column
results$viterbi <- viterbi(hmm, obs)
results$posterior <- posterior(hmm, obs)[1, ]
results$posterior[results$posterior >= 0.5] <- "FAIR"
results$posterior[results$posterior < 0.5] <- "LOADED"
# Check out results
table(results$dice)
table(results$viterbi)
table(results$posterior)
### Plot predictions with true sequence
p1 <- ggplot(aes(x = seq_along(dice)), data = results) +
geom_point(aes(y = dice)) +
ylab("State") + xlab("Dice Roll (In Sequence)") + ylab("State") +
ggtitle("Actual Results")
p2 <- ggplot(aes(x = seq_along(dice)), data = results) +
geom_point(aes(y = dice), color = "#F8766D") +
geom_point(aes(y = viterbi), color = "#00BFC4") +
xlab("Dice Roll (In Sequence)") + ylab("State") +
ggtitle("Viterbi Predictions")
p3 <- ggplot(aes(x = seq_along(dice)), data = results) +
geom_point(aes(y = dice), color = "#F8766D") +
geom_point(aes(y = posterior), color = "#00BFC4") +
xlab("Dice Roll (in sequence)") + ylab("State") +
ggtitle("Posterior Predictions")
grid.arrange(p1, p2, p3, ncol = 1)
### Plot predictions with true sequence
p1 <- ggplot(aes(x = seq_along(dice)), data = results) +
geom_point(aes(y = dice)) +
ylab("State") + xlab("Dice Roll (In Sequence)") + ylab("State") +
ggtitle("Actual Results")
head(table2)
library(DMwR)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
trainIndex
head(trainIndex)
head(adData)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
testIndex
createDataPartition(diagnosis, p = 0.50,list=FALSE)
head(createDataPartition(diagnosis, p = 0.50,list=FALSE))
createDataPartition(diagnosis,p=0.5,list=FALSE)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
head(training)
tail(training)
head(testing)
tail(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(trainig)
head(training
)
## for turning continuous covariates into factors). What do you notice in these plots?
library(Hmisc)
library(plyr)
splitOn <- cut2(training$Age, g = 4)
splitOn <- mapvalues(splitOn,
from = levels(factor(splitOn)),
to = c("red", "blue", "yellow", "green"))
SplitOn
splitOn
plot(training$CompressiveStrength, col = splitOn)
#Load the Alzheimer's disease data using the commands:
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
answers = rep("A", 20)
answers
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
olive
newdata = as.data.frame(t(colMeans(olive)))
newdata
library(randomForest)
model <- train(Area ~ ., data = olive, method = "rpart2")
model
predict(model, newdata=newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
logitModel <-train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial"))
logitModel <-train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
predtrain = predict(logitModel, newdata=trainSA)
predtest = predict(logitModel, newdata=testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(trainSA$chd,predtrain) #
missClass(testSA$chd,predtest) #0.277
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
a
b <- varImp(a)
order(b)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
a
order(varImp(a), decreasing=T)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
# Load Dependeicies
library(caret)
library(randomForest)
library(readr)
library(lubridate)
library(plyr)
library(doMC)
registerDoMC(cores = 4)
setwd("/Users/bikash/repos/kaggleCompetition1/RossmannStoreSales")
# Set seed
set.seed(12345)
train <- read_csv("data/train.csv")
test  <- read_csv("data/test.csv")
store <- read_csv("data/store.csv")
# Merge Store stuff
train <- merge(train, store, by=c('Store'))
test <- merge(test, store, by=c('Store'))
test <- arrange(test,Id)
# Only evaludated on Open days
train <- train[ which(train$Open=='1'),]
train$Open <- NULL
test$Open <- NULL
# Set missing data to 0
train[is.na(train)] <- 0
test[is.na(test)] <- 0
# Date stuff
train$Date <- ymd(train$Date)
test$Date <- ymd(test$Date)
train$day <- as.factor(day(train$Date))
test$day <- as.factor(day(test$Date))
train$month <- as.factor(month(train$Date))
test$month <- as.factor(month(test$Date))
train$year <- as.factor(year(train$Date))
test$year <- as.factor(year(test$Date))
train$Date <- NULL
test$Date <- NULL
# always 1 for training and test
train$StateHoliday <- NULL
test$StateHoliday <- NULL
#Factorize stuff
train$DayOfWeek <- as.factor(train$DayOfWeek)
test$DayOfWeek <- as.factor(test$DayOfWeek)
train$Promo <- as.factor(train$Promo)
test$Promo <- as.factor(test$Promo)
train$SchoolHoliday <- as.factor(train$SchoolHoliday)
test$SchoolHoliday <- as.factor(test$SchoolHoliday)
# Factorize store stuff
train$StoreType <- as.factor(train$StoreType)
test$StoreType <- as.factor(test$StoreType)
train$Assortment <- as.factor(train$Assortment)
test$Assortment <- as.factor(test$Assortment)
train$CompetitionDistance <- as.numeric(train$CompetitionDistance)
test$CompetitionDistance <- as.numeric(test$CompetitionDistance)
train$Promo2 <- as.factor(train$Promo2)
test$Promo2 <- as.factor(test$Promo2)
train$PromoInterval <- as.factor(train$PromoInterval)
test$PromoInterval <- as.factor(test$PromoInterval)
competition_start <- strptime('20.10.2015', format='%d.%m.%Y')
train$CompetitionDaysOpen <- as.numeric(difftime(competition_start,
strptime(paste('1',
train$CompetitionOpenSinceMonth,
train$CompetitionOpenSinceYear, sep = '.'),
format='%d.%m.%Y'), units='days'))
test$CompetitionDaysOpen <- as.numeric(difftime(competition_start,
strptime(paste('1',
test$CompetitionOpenSinceMonth,
test$CompetitionOpenSinceYear, sep = '.'),
format='%d.%m.%Y'), units='days'))
train$CompetitionDaysOpen[is.na(train$CompetitionDaysOpen)] <- 0
test$CompetitionDaysOpen[is.na(test$CompetitionDaysOpen)] <- 0
train$CompetitionWeeksOpen <- train$CompetitionDaysOpen/7
test$CompetitionWeeksOpen <- test$CompetitionDaysOpen/7
train$CompetitionMonthsOpen <- train$CompetitionDaysOpen/30
test$CompetitionMonthsOpen <- test$CompetitionDaysOpen/30
train$CompetitionYearsOpen <- train$CompetitionWeeksOpen/52
test$CompetitionYearsOpen <- test$CompetitionWeeksOpen/52
train$CompetitionOpenSinceMonth <- NULL
train$CompetitionOpenSinceYear <- NULL
test$CompetitionOpenSinceMonth <- NULL
test$CompetitionOpenSinceYear <- NULL
# target variables
train$Sales <- as.numeric(train$Sales)
train$Customers <- NULL #as.numeric(train$Customers)
train$Sales <- log(train$Sales+1)
head(train)
tail(train)
train$PromoInterval <-NULL
test$PromoInterval <-NULL
set.seed(1234)
fitControl <- trainControl(method="cv", number=3, verboseIter=T)
rfFit <- train(Sales ~.,
method="rf", data=train, ntree=50, importance=TRUE,
sampsize=100000,
do.trace=10, trControl=fitControl)
pred <- predict(rfFit, test)
submit = data.frame(Id = test$Id, Sales = (exp(pred) -1))
write.csv(submit, "output/rf_better_features.csv", row.names = FALSE, quote = FALSE)
write.csv(submit, "output/rf_sub.csv", row.names = FALSE, quote = FALSE)
submit
